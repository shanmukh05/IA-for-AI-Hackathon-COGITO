{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HackerEarth_Intelligence_Challenge_OpenL3_embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKlA5tTk920w"
      },
      "source": [
        "! pip install -q kaggle --upgrade\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDlErHybDLmU"
      },
      "source": [
        "# Download data from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WC9BG5t_983T"
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d shanmukh05/intelligence-augmentation-ia-for-ai"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpVwqBocDPgs"
      },
      "source": [
        "## Unzip data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_xAayhI-DJO"
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "path = \"/content/intelligence-augmentation-ia-for-ai.zip\"\n",
        "zipref = zipfile.ZipFile(path, \"r\")\n",
        "zipref.extractall(\"/content/\")\n",
        "zipref.close()\n",
        "os.remove(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYKlirZvDUb0"
      },
      "source": [
        "## Importing necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHCCjkQ1brLE"
      },
      "source": [
        "!pip install -q tensorflow==2.4.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNKD58dO-NY0"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import KFold,StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFhrjfSMDZAK"
      },
      "source": [
        "# Constants Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hSrnCtz-PNr"
      },
      "source": [
        "train_df = pd.read_csv(\"/content/dataset/dataset/train.csv\")\n",
        "test_df = pd.read_csv(\"/content/dataset/dataset/test.csv\")\n",
        "\n",
        "train_df[\"filename\"] = train_df[\"filename\"].map(lambda x : x.split(\".\")[0]+\".wav\")\n",
        "\n",
        "TRAIN_PATH = \"/content/train/train\"\n",
        "TEST_PATH = \"/content/test/test\"\n",
        "\n",
        "#os.remove(os.path.join(TRAIN_PATH,\"38543.wav\"))\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "NUM_CLASSES = 7\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "PATH_LS = tf.io.gfile.glob(TRAIN_PATH + \"/*\")\n",
        "FILES_LS = [path.split(\"/\")[-1] for path in PATH_LS]\n",
        "\n",
        "TEST_FILES_LS = list(test_df.filename.values)\n",
        "TEST_PATH_LS = [os.path.join(TEST_PATH,f) for f in TEST_FILES_LS]\n",
        "\n",
        "EMBED_SIZE = 512\n",
        "MIN_SIZE = 16000\n",
        "TOTAL_EMBED = 46107\n",
        "\n",
        "id2label = {\n",
        "    0 : \"anger\",\n",
        "    1 : \"disgust\",\n",
        "    2 : \"fear\",\n",
        "    3 : \"joy\",\n",
        "    4 : \"neutral\",\n",
        "    5 : \"sadness\",\n",
        "    6 : \"surprise\",\n",
        "}\n",
        "label2id = {value:key for key,value in id2label.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3FST81dDcr7"
      },
      "source": [
        "# OpenL3 Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4lNed2L3PI1"
      },
      "source": [
        "!pip install -q SoundFile\n",
        "!pip install -q openl3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XApI-ZvDAz1v"
      },
      "source": [
        "import openl3\n",
        "import soundfile as sf\n",
        "model_openl3 = openl3.models.load_audio_embedding_model(input_repr=\"mel128\", content_type=\"env\",embedding_size=512)\n",
        "\n",
        "def get_embed_openl3(path):\n",
        "    audio, sr = sf.read(path)\n",
        "    emb, ts = openl3.get_audio_embedding(audio, sr,model=model_openl3, hop_size=0.5, verbose=0)\n",
        "    return emb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uheQJKQADu2D"
      },
      "source": [
        "## Train Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNLB8ty3ykx5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b27028b-9cea-4042-f7f6-088bb8c92515"
      },
      "source": [
        "train_embed = []\n",
        "count = 0\n",
        "\n",
        "for path in tqdm(PATH_LS):\n",
        "    #arr = get_embed_vggish(path)\n",
        "    arr = get_embed_openl3(path)\n",
        "    count += arr.shape[0]\n",
        "    train_embed.append(arr)\n",
        "\n",
        "TOTAL_EMBED = count\n",
        "#labels = np.zeros((len(FILES_LS),NUM_CLASSES))\n",
        "tmp_labels = np.zeros((len(FILES_LS)))\n",
        "files_df = pd.DataFrame(PATH_LS, columns = [\"filepath\"])\n",
        "\n",
        "for i in range(len(FILES_LS)):\n",
        "    label_id = label2id[train_df[train_df[\"filename\"] == FILES_LS[i]][\"emotion\"].values[0]]\n",
        "    #labels[i][label_id] = 1\n",
        "    tmp_labels[i] = label_id\n",
        "print(\"Temp Train Embeddings\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Temp Train Embeddings\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1lqpvTMCsFV"
      },
      "source": [
        "train_arr = np.zeros((TOTAL_EMBED,EMBED_SIZE))\n",
        "#label_onehot = np.zeros((TOTAL_EMBED,NUM_CLASSES))\n",
        "label_class = np.zeros((TOTAL_EMBED))\n",
        "tot_count = 0\n",
        "\n",
        "for i in tqdm(range(len(train_embed))):\n",
        "    size = train_embed[i].shape[0]\n",
        "    train_arr[tot_count:tot_count+size] = train_embed[i]\n",
        "    #label_onehot[tot_count:tot_count+size] = labels[i]\n",
        "    label_class[tot_count:tot_count+size] = tmp_labels[i]\n",
        "    tot_count+=size\n",
        "\n",
        "del train_embed,tmp_labels\n",
        "np.save(\"./train_embed.npy\",train_arr)\n",
        "np.save(\"./train_label.npy\",label_class)\n",
        "print(\"Train Embeddings\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DMPl6jTDyY5"
      },
      "source": [
        "## Test Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOarfXsTZPTg"
      },
      "source": [
        "test_embed = []\n",
        "import shutil\n",
        "os.mkdir(\"./test_embed\")\n",
        "for path in tqdm(TEST_PATH_LS):\n",
        "    name = path.split(\"/\")[-1].split(\".\")[0]\n",
        "    path = path.split(\".\")[0] + \".wav\"\n",
        "    #test_embed.append(get_embed_vggish(path))\n",
        "    arr = get_embed_openl3(path)\n",
        "    test_embed.append(arr)\n",
        "    np.save(f\"./test_embed/{name}.npy\",arr)\n",
        "!zip -r test_embed.zip ./test_embed/\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "shutil.copyfile(\"./train_embed.npy\",\"/content/gdrive/MyDrive/MNIST/train_embed.npy\")\n",
        "shutil.copyfile(\"./train_label.npy\",\"/content/gdrive/MyDrive/MNIST/train_label.npy\")\n",
        "shutil.copyfile(\"./test_embed.zip\",\"/content/gdrive/MyDrive/MNIST/test_embed.zip\")\n",
        "\n",
        "print(\"Test Embeddings\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n56D-nIJ1L7I"
      },
      "source": [
        "# Load Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYdJxBn2wPON"
      },
      "source": [
        "train_arr = np.load(\"/content/embeddings_512_env_mel256/train_embed.npy\")\n",
        "label_class = np.load(\"/content/embeddings_512_env_mel256/train_label.npy\")\n",
        "\n",
        "TEST_EMBED_PATH = \"/content/embeddings_512_env_mel256/test_embed/test_embed/\"\n",
        "TEST_EMBED_LS = tf.io.gfile.glob(TEST_EMBED_PATH+\"*.npy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rKYqOcA1A7i"
      },
      "source": [
        "# Normal Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i1Pf1yxGTZ5"
      },
      "source": [
        "clf = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=3, weights = \"distance\"))\n",
        "clf.fit(train_arr,label_class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8722uts0s9_"
      },
      "source": [
        "# Soft Label\n",
        "\n",
        "pred_ls = []\n",
        "for i,f in tqdm(enumerate(TEST_FILES_LS)):\n",
        "    name = f.split(\".\")[0] + \".npy\"\n",
        "    path = os.path.join(TEST_EMBED_PATH, name)\n",
        "    emb = np.load(path)\n",
        "    count = emb.shape[0]\n",
        "    probs = clf.predict_proba(emb)\n",
        "    probs = np.sum(probs,axis=0)/count\n",
        "    pred_ls.append(id2label[np.argmax(probs)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3W2JWZFGLpp"
      },
      "source": [
        "# Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lj5rcmPYGrAh"
      },
      "source": [
        "from sklearn.model_selection import KFold,StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "SEED = 2021\n",
        "N_SPLITS = 4\n",
        "clfs = []\n",
        "kfold = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
        "\n",
        "for fold,(tID,vID) in enumerate(kfold.split(train_arr,label_class)):\n",
        "    tArr, tLabels =  train_arr[tID], label_class[tID]\n",
        "    vArr, vLabels =  train_arr[vID], label_class[vID]\n",
        "    print(\"Number of Training Samples: \",len(tID))\n",
        "    print(\"Number of Validation Samples: \",len(vID))\n",
        "    \n",
        "    clf = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=3, weights = \"distance\")) #MinMaxScaler(), Normalizer()\n",
        "    #clf = clf = KNeighborsClassifier(n_neighbors=3)\n",
        "    clf = make_pipeline(StandardScaler(), PCA(n_components=224), KNeighborsClassifier(n_neighbors=3, weights = \"distance\"))\n",
        "    clf.fit(tArr, tLabels)\n",
        "    clfs.append(clf)\n",
        "   \n",
        "    #print(f\"Score of Training data for fold - {fold+1} : {accuracy_score(tLabels, clf.predict(tArr))}\")\n",
        "    print(f\"Score of Validation data for fold - {fold+1} : {accuracy_score(vLabels, clf.predict(vArr))} \\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BdJUD0DGPLh"
      },
      "source": [
        "pred_ls = []\n",
        "for i,f in tqdm(enumerate(TEST_FILES_LS)):\n",
        "    name = f.split(\".\")[0] + \".npy\"\n",
        "    path = os.path.join(TEST_EMBED_PATH, name)\n",
        "    emb = np.load(path)\n",
        "    count = emb.shape[0]\n",
        "    tot = 0\n",
        "    for clf in clfs:\n",
        "      probs = clf.predict_proba(emb)\n",
        "      probs = np.sum(probs,axis=0)/count\n",
        "      tot += probs\n",
        "    tot /= len(clfs)\n",
        "    pred_ls.append(id2label[np.argmax(tot)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThcIGf9PGngJ"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzf4OUuj05Lj"
      },
      "source": [
        "result_df = pd.DataFrame.from_dict({\n",
        "    \"filename\" : TEST_FILES_LS,\n",
        "    \"emotion\" : pred_ls\n",
        "})\n",
        "result_df.to_csv(\"./submission.csv\",index=False)\n",
        "result_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TIBD3qb8Swo"
      },
      "source": [
        "result_df.emotion.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biULc6z6CCeN"
      },
      "source": [
        "## Download model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHDAxYuiIdng"
      },
      "source": [
        "import pickle\n",
        "with open('./model.pkl','wb') as f:\n",
        "    pickle.dump(clf,f)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}